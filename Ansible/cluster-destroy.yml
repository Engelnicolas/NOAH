---
- name: Comprehensive NOAH Kubernetes Cluster Destruction
  hosts: localhost
  gather_facts: true
  vars:
    default_cluster_name: "noah-cluster"
    k3s_data_dir: "/var/lib/rancher/k3s"
    k3s_config_dir: "/etc/rancher/k3s"
    system_namespaces:
      - kube-system
      - kube-public
      - kube-node-lease
      - default
    
  tasks:
    - name: Check if kubectl is available
      ansible.builtin.command: which kubectl
      register: kubectl_check
      ignore_errors: true
      changed_when: false

    - name: Check if K3s is running
      ansible.builtin.command: systemctl is-active k3s
      register: k3s_status
      ignore_errors: true
      changed_when: false

    - name: "PREREQUISITE: Delete all Helm releases (including NOAH components)"
      ansible.builtin.shell: |
        echo "=== DELETING ALL HELM RELEASES ==="
        helm list --all-namespaces -o json | \
        jq -r '.[] | "\(.name) \(.namespace)"' | \
        while read name namespace; do
          echo "Uninstalling Helm release: $name from namespace: $namespace"
          helm uninstall "$name" -n "$namespace" --timeout=120s --wait || true
        done
        echo "=== HELM CLEANUP COMPLETED ==="
      when: kubectl_check.rc == 0
      ignore_errors: true

    - name: "PREREQUISITE: Force delete all NOAH application pods"
      ansible.builtin.shell: |
        echo "=== DELETING NOAH PODS ==="
        # Delete pods with specific NOAH labels
        kubectl get pods --all-namespaces -l "noah.infra.com/managed-by=noah-cli" -o json 2>/dev/null | \
        jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | \
        while read namespace pod; do
          echo "Force deleting NOAH pod: $pod in namespace: $namespace"
          kubectl delete pod "$pod" -n "$namespace" --force --grace-period=0 || true
        done
        
        # Delete all pods in NOAH-related namespaces
        for ns in identity monitoring ingress-nginx cilium-system; do
          echo "Force deleting all pods in namespace: $ns"
          kubectl get pods -n "$ns" -o name 2>/dev/null | \
          xargs -r kubectl delete -n "$ns" --force --grace-period=0 || true
        done
        echo "=== NOAH PODS CLEANUP COMPLETED ==="
      when: kubectl_check.rc == 0
      ignore_errors: true

    - name: "PREREQUISITE: Delete all NOAH secrets and configmaps"
      ansible.builtin.shell: |
        echo "=== DELETING NOAH SECRETS AND CONFIGMAPS ==="
        # Delete NOAH-specific secrets
        kubectl get secrets --all-namespaces -l "noah.infra.com/component" -o json 2>/dev/null | \
        jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | \
        while read namespace secret; do
          echo "Deleting NOAH secret: $secret from namespace: $namespace"
          kubectl delete secret "$secret" -n "$namespace" || true
        done
        
        # Delete NOAH-specific configmaps
        kubectl get configmaps --all-namespaces -l "noah.infra.com/component" -o json 2>/dev/null | \
        jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | \
        while read namespace cm; do
          echo "Deleting NOAH configmap: $cm from namespace: $namespace"
          kubectl delete configmap "$cm" -n "$namespace" || true
        done
        
        # Delete specific NOAH secrets by name pattern
        for pattern in authentik samba4 cilium noah; do
          kubectl get secrets --all-namespaces --field-selector metadata.name~="$pattern" -o json 2>/dev/null | \
          jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | \
          while read namespace secret; do
            echo "Deleting secret by pattern: $secret from namespace: $namespace"
            kubectl delete secret "$secret" -n "$namespace" || true
          done
        done
        echo "=== SECRETS AND CONFIGMAPS CLEANUP COMPLETED ==="
      when: kubectl_check.rc == 0
      ignore_errors: true

    - name: "PREREQUISITE: Delete all non-system namespaces"
      ansible.builtin.shell: |
        echo "=== DELETING NON-SYSTEM NAMESPACES ==="
        kubectl get namespaces -o json | \
        jq -r '.items[] | select(.metadata.name | test("^(kube-system|kube-public|kube-node-lease|default)$") | not) | .metadata.name' | \
        while read namespace; do
          echo "Deleting namespace: $namespace"
          kubectl delete namespace "$namespace" --timeout=60s --force --grace-period=0 || true
        done
        echo "=== NAMESPACE CLEANUP COMPLETED ==="
      when: kubectl_check.rc == 0
      ignore_errors: true

    - name: "PREREQUISITE: Validate clean state"
      ansible.builtin.shell: |
        echo "=== VALIDATING CLUSTER CLEAN STATE ==="
        
        # Check for remaining NOAH pods
        remaining_pods=$(kubectl get pods --all-namespaces --field-selector metadata.namespace!=kube-system,metadata.namespace!=kube-public,metadata.namespace!=kube-node-lease,metadata.namespace!=default -o name 2>/dev/null | wc -l)
        echo "Remaining non-system pods: $remaining_pods"
        
        # Check for remaining Helm releases
        remaining_releases=$(helm list --all-namespaces -o json | jq '. | length')
        echo "Remaining Helm releases: $remaining_releases"
        
        # Check for remaining non-system namespaces
        remaining_namespaces=$(kubectl get namespaces -o json | jq -r '.items[] | select(.metadata.name | test("^(kube-system|kube-public|kube-node-lease|default)$") | not) | .metadata.name' | wc -l)
        echo "Remaining non-system namespaces: $remaining_namespaces"
        
        echo "=== CLUSTER STATE VALIDATION COMPLETED ==="
        echo "Prerequisites met: Cluster is clean and ready for redeployment"
      when: kubectl_check.rc == 0
      ignore_errors: true
      register: validation_result

    - name: Stop K3s service
      ansible.builtin.systemd:
        name: k3s
        state: stopped
        enabled: false
      ignore_errors: true
      when: k3s_status.rc == 0

    - name: Kill any remaining K3s processes
      ansible.builtin.shell: |
        pkill -f k3s || true
        pkill -f containerd-shim || true
        sleep 5
        pkill -9 -f k3s || true
      ignore_errors: true

    - name: Unmount K3s filesystems
      ansible.builtin.shell: |
        umount $(mount | grep '/var/lib/rancher/k3s' | awk '{print $3}') 2>/dev/null || true
        umount $(mount | grep '/run/k3s' | awk '{print $3}') 2>/dev/null || true
      ignore_errors: true

    - name: Remove K3s data directories
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      loop:
        - "{{ k3s_data_dir }}"
        - "{{ k3s_config_dir }}"
        - "/run/k3s"
        - "/var/lib/kubelet"
        - "/var/lib/cni"
        - "/opt/cni"
      ignore_errors: true

    - name: Remove K3s binary and systemd service
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      loop:
        - "/usr/local/bin/k3s"
        - "/etc/systemd/system/k3s.service"
        - "/etc/systemd/system/k3s-agent.service"
      ignore_errors: true
      become: yes

    - name: Reload systemd daemon
      ansible.builtin.systemd:
        daemon_reload: yes
      ignore_errors: true
      become: yes

    - name: Clean container images (optional)
      ansible.builtin.shell: |
        # Clean up any remaining container images
        if command -v crictl >/dev/null 2>&1; then
          crictl rmi --prune || true
        fi
        if command -v docker >/dev/null 2>&1; then
          docker system prune -af || true
        fi
      ignore_errors: true

    - name: Final validation - Verify complete destruction
      ansible.builtin.shell: |
        echo "=== FINAL DESTRUCTION VALIDATION ==="
        
        # Check if K3s is still running
        if systemctl is-active k3s >/dev/null 2>&1; then
          echo "WARNING: K3s service is still active"
        else
          echo "✓ K3s service stopped"
        fi
        
        # Check for remaining K3s processes
        k3s_processes=$(pgrep -f k3s | wc -l)
        echo "Remaining K3s processes: $k3s_processes"
        
        # Check for data directories
        for dir in "{{ k3s_data_dir }}" "{{ k3s_config_dir }}" "/run/k3s"; do
          if [ -d "$dir" ]; then
            echo "WARNING: Directory still exists: $dir"
          else
            echo "✓ Directory removed: $dir"
          fi
        done
        
        echo "=== DESTRUCTION VALIDATION COMPLETED ==="
        echo "Cluster destruction completed successfully"
        echo "System is ready for fresh cluster creation"
      ignore_errors: true

    - name: Display destruction summary
      debug:
        msg:
          - "=== NOAH CLUSTER DESTRUCTION COMPLETE ==="
          - "✓ All Helm releases uninstalled"
          - "✓ All NOAH pods and secrets removed"  
          - "✓ All non-system namespaces deleted"
          - "✓ K3s service stopped and data removed"
          - "✓ System validated and ready for redeployment"
          - ""
          - "Next step: Run 'python noah.py cluster create' to create a fresh cluster"
